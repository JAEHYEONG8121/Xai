## SHAP (Shapley Additive Explanations)
üì¢ PyTorch Implementation Based on the Original Paper
This project is based on the paper "A Unified Approach to Interpreting Model Predictions" (Lundberg & Lee, 2017)
and implements SHAP using PyTorch from scratch.

### 1. What is SHAP?
SHAP (Shapley Additive Explanations) is a game-theoretic approach to explain the output of any machine learning model.
It quantifies the contribution of each input feature to the final prediction.

**‚úÖ Key Concepts of SHAP**
  - Evaluates the model's output changes by adding or removing features.
  - Fairly distributes the model's prediction among individual feature contributions.
  - Considers all possible feature combinations to compare the average contribution of each feature.

**üí° Why SHAP?** <br/>
- Provides consistent and fair feature attribution based on Shapley values. Works for both classification and regression models. Offers global (entire dataset) and local (single prediction) explanations.

**üåü Key Principles** <br/>
1Ô∏è‚É£ Perturbation ‚Üí Generate variations of the original input by removing/altering features.<br/>
2Ô∏è‚É£ Shapley Value Calculation ‚Üí Compute the marginal contribution of each feature using coalitional game theory.<br/>
3Ô∏è‚É£ Local Explanations ‚Üí Aggregate contributions to explain a model‚Äôs decision for a specific instance.
